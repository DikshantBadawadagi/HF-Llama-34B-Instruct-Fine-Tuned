# Uninstall conflicting packages and clear environment
!pip uninstall -y transformers torch torchaudio torchvision accelerate bitsandbytes huggingface_hub peft fastai timm
!pip cache purge

# Install compatible versions of required libraries
!pip install torch==2.4.1 torchvision==0.19.1 transformers==4.45.1 accelerate==0.33.0 bitsandbytes==0.43.3 huggingface_hub==0.25.1

# Import necessary libraries
import os
import torch
import requests
from PIL import Image
from transformers import MllamaForConditionalGeneration, AutoProcessor, BitsAndBytesConfig
from google.colab import files

# Set Hugging Face token (use Colab secrets or environment variable)
os.environ['HF_TOKEN'] = ""  # Replace with your token

# Log in to Hugging Face
from huggingface_hub import login
login(token=os.environ['HF_TOKEN'], add_to_git_credential=False)

# Model ID for Llama 3.2 11B Vision Instruct
model_id = "meta-llama/Llama-3.2-11B-Vision-Instruct"

# Define 4-bit quantization configuration
quantization_config = BitsAndBytesConfig(
    load_in_4bit=True,
    bnb_4bit_quant_type="nf4",
    bnb_4bit_compute_dtype=torch.bfloat16,
    bnb_4bit_use_double_quant=True
)

# Load the processor
try:
    processor = AutoProcessor.from_pretrained(model_id)
except Exception as e:
    print(f"Error loading processor: {e}")
    raise

# Load the model with 4-bit quantization to fit on T4 GPU
try:
    model = MllamaForConditionalGeneration.from_pretrained(
        model_id,
        quantization_config=quantization_config,
        torch_dtype=torch.bfloat16,
        device_map="auto"
    )
    # Tie model weights to resolve accelerate warning
    model.tie_weights()
    # Enable gradient checkpointing to reduce memory usage
    model.gradient_checkpointing_enable()
except Exception as e:
    print(f"Error loading model: {e}")
    raise

# Function to download and process an image from URL
def load_image_from_url(image_url):
    try:
        image = Image.open(requests.get(image_url, stream=True).raw).convert("RGB")
        return image
    except Exception as e:
        print(f"Error loading image from URL: {e}")
        return None

# Function to process an uploaded image
def load_image_from_upload():
    uploaded = files.upload()
    if not uploaded:
        print("No image uploaded.")
        return None
    image_path = list(uploaded.keys())[0]
    try:
        image = Image.open(image_path).convert("RGB")
        return image
    except Exception as e:
        print(f"Error loading uploaded image: {e}")
        return None

# Define the prompt for injury detection
prompt = """
<|image|>Analyze the image for any visible injuries or signs [1]: https://example.com/injury.jpgvisible injuries or signs of injury. Provide a detailed description including:
- Location of the injury (e.g., arm, leg, head).
- Type of injury (e.g., cut, bruise, burn).
- Severity (e.g., minor, moderate, severe), if detectable.
If no injuries are visible, state so clearly.
"""

# Choose image input method: URL or upload
print("Choose image input method:")
print("1. Enter a URL")
print("2. Upload an image")
choice = input("Enter 1 or 2: ")

if choice == "1":
    image_url = input("Enter the image URL: ")
    image = load_image_from_url(image_url)
elif choice == "2":
    image = load_image_from_upload()
else:
    print("Invalid choice. Exiting.")
    image = None

# Process inputs and generate output
if image:
    try:
        inputs = processor(
            text=prompt,
            images=[image],
            return_tensors="pt"
        ).to(model.device)

        # Generate output
        output = model.generate(
            **inputs,
            max_new_tokens=200,
            do_sample=False,
            temperature=0.0
        )

        # Decode and print the response
        response = processor.decode(output[0], skip_special_tokens=True)
        print("\nModel Response:")
        print(response)
    except Exception as e:
        print(f"Error during inference: {e}")
else:
    print("No valid image provided. Please try again.")


#https://res.cloudinary.com/duamc11un/image/upload/v1741199298/frpioegnwu5rbu5xivwu.jpg
#https://colab.research.google.com/gist/DikshantBadawadagi/89246f669c73942aceb01c030f544799/untitled30.ipynb#scrollTo=QvJS7X9JlUsJ
